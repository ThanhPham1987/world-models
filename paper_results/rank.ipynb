{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesg/research/ordinal-probing\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.stats import rankdata\n",
    "from load import load_model\n",
    "import datasets\n",
    "import seaborn as sns\n",
    "\n",
    "from feature_datasets.common import *\n",
    "import utils\n",
    "import os\n",
    "\n",
    "from save_activations import load_activation_probing_dataset\n",
    "from probe_experiment import load_probe_results\n",
    "from analysis.generalization import*\n",
    "from analysis.probe_plots import *\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LAYER = {\n",
    "    'Llama-2-7b-hf': 20,\n",
    "    'Llama-2-13b-hf': 24,\n",
    "    'Llama-2-70b-hf': 48,\n",
    "}\n",
    "\n",
    "ACTIVATION_CONFIGS = {\n",
    "    'World Map': ('world_place', 'coords'),\n",
    "    'USA Map': ('us_place', 'where_us'),\n",
    "    # 'NYC Map': ('nyc_place', 'where_nyc_normalized'),\n",
    "    # 'Historical Figures': ('historical_figure', 'empty'),\n",
    "    # 'Entertainment': ('art', 'release'),\n",
    "    # 'Headlines': ('headline', 'article_w_period'),\n",
    "}\n",
    "\n",
    "activations = {}\n",
    "for name, (entity_type, prompt_name) in ACTIVATION_CONFIGS.items():\n",
    "    for model, layer in MODEL_LAYER.items():\n",
    "        activations[(name, model)] = load_activation_probing_dataset(\n",
    "            model, entity_type, prompt_name, layer).dequantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_df = load_entity_data('world_place')\n",
    "us_df = load_entity_data('us_place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>entity_subtype</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>has_thumbnail</th>\n",
       "      <th>page_views</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>total_area</th>\n",
       "      <th>population</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tancredo Neves Pantheon of the Fatherland and ...</td>\n",
       "      <td>Monument</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>-15.80170</td>\n",
       "      <td>-47.86030</td>\n",
       "      <td>1</td>\n",
       "      <td>7521.0</td>\n",
       "      <td>structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sembuwatta Lake</td>\n",
       "      <td>AmusementParkAttraction</td>\n",
       "      <td>Sri_Lanka</td>\n",
       "      <td>7.43694</td>\n",
       "      <td>80.69970</td>\n",
       "      <td>1</td>\n",
       "      <td>16340.0</td>\n",
       "      <td>structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ford Rotunda</td>\n",
       "      <td>AmusementParkAttraction</td>\n",
       "      <td>United_States</td>\n",
       "      <td>42.31210</td>\n",
       "      <td>-83.17670</td>\n",
       "      <td>1</td>\n",
       "      <td>40773.0</td>\n",
       "      <td>structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afsluitdijk</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>53.00000</td>\n",
       "      <td>5.16667</td>\n",
       "      <td>1</td>\n",
       "      <td>227321.0</td>\n",
       "      <td>structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mudeirej Bridge</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>33.80080</td>\n",
       "      <td>35.72710</td>\n",
       "      <td>1</td>\n",
       "      <td>5623.0</td>\n",
       "      <td>structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39580</th>\n",
       "      <td>La Poudre Pass Lake</td>\n",
       "      <td>NaturalPlace</td>\n",
       "      <td>United_States</td>\n",
       "      <td>40.47330</td>\n",
       "      <td>-105.82500</td>\n",
       "      <td>0</td>\n",
       "      <td>19310.0</td>\n",
       "      <td>natural_place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39581</th>\n",
       "      <td>Lac Le Jeune</td>\n",
       "      <td>NaturalPlace</td>\n",
       "      <td>Canada</td>\n",
       "      <td>50.48300</td>\n",
       "      <td>-120.47700</td>\n",
       "      <td>1</td>\n",
       "      <td>7050.0</td>\n",
       "      <td>natural_place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39582</th>\n",
       "      <td>Khatanga Gulf</td>\n",
       "      <td>NaturalPlace</td>\n",
       "      <td>Russia</td>\n",
       "      <td>73.75000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>16258.0</td>\n",
       "      <td>natural_place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39583</th>\n",
       "      <td>Karimata Strait</td>\n",
       "      <td>NaturalPlace</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>-2.08333</td>\n",
       "      <td>108.66700</td>\n",
       "      <td>1</td>\n",
       "      <td>32778.0</td>\n",
       "      <td>natural_place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39584</th>\n",
       "      <td>Kawagama Lake</td>\n",
       "      <td>NaturalPlace</td>\n",
       "      <td>Canada</td>\n",
       "      <td>45.29860</td>\n",
       "      <td>-78.75250</td>\n",
       "      <td>0</td>\n",
       "      <td>11795.0</td>\n",
       "      <td>natural_place</td>\n",
       "      <td>32000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39585 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0      Tancredo Neves Pantheon of the Fatherland and ...   \n",
       "1                                        Sembuwatta Lake   \n",
       "2                                           Ford Rotunda   \n",
       "3                                            Afsluitdijk   \n",
       "4                                        Mudeirej Bridge   \n",
       "...                                                  ...   \n",
       "39580                                La Poudre Pass Lake   \n",
       "39581                                       Lac Le Jeune   \n",
       "39582                                      Khatanga Gulf   \n",
       "39583                                    Karimata Strait   \n",
       "39584                                      Kawagama Lake   \n",
       "\n",
       "                entity_subtype        country  latitude  longitude  \\\n",
       "0                     Monument         Brazil -15.80170  -47.86030   \n",
       "1      AmusementParkAttraction      Sri_Lanka   7.43694   80.69970   \n",
       "2      AmusementParkAttraction  United_States  42.31210  -83.17670   \n",
       "3                       Bridge    Netherlands  53.00000    5.16667   \n",
       "4                       Bridge        Lebanon  33.80080   35.72710   \n",
       "...                        ...            ...       ...        ...   \n",
       "39580             NaturalPlace  United_States  40.47330 -105.82500   \n",
       "39581             NaturalPlace         Canada  50.48300 -120.47700   \n",
       "39582             NaturalPlace         Russia  73.75000  109.00000   \n",
       "39583             NaturalPlace      Indonesia  -2.08333  108.66700   \n",
       "39584             NaturalPlace         Canada  45.29860  -78.75250   \n",
       "\n",
       "       has_thumbnail  page_views    entity_type  total_area  population  \\\n",
       "0                  1      7521.0      structure         NaN         NaN   \n",
       "1                  1     16340.0      structure         NaN         NaN   \n",
       "2                  1     40773.0      structure         NaN         NaN   \n",
       "3                  1    227321.0      structure         NaN         NaN   \n",
       "4                  1      5623.0      structure         NaN         NaN   \n",
       "...              ...         ...            ...         ...         ...   \n",
       "39580              0     19310.0  natural_place         NaN         NaN   \n",
       "39581              1      7050.0  natural_place         NaN         NaN   \n",
       "39582              1     16258.0  natural_place         NaN         NaN   \n",
       "39583              1     32778.0  natural_place         NaN         NaN   \n",
       "39584              0     11795.0  natural_place  32000000.0         NaN   \n",
       "\n",
       "       is_test  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  \n",
       "...        ...  \n",
       "39580    False  \n",
       "39581     True  \n",
       "39582     True  \n",
       "39583     True  \n",
       "39584    False  \n",
       "\n",
       "[39585 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test = us_df.state_id.values == 'CA'\n",
    "y = us_df.latitude.values\n",
    "x = us_df.longitude.values\n",
    "\n",
    "x_train_rank = rankdata(x[~is_test])\n",
    "x_test_rank = rankdata(x[is_test])\n",
    "y_train_rank = rankdata(y[~is_test])\n",
    "y_test_rank = rankdata(y[is_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes.rank import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = activations[('USA Map', 'Llama-2-70b-hf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29997, 8192])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_probe = SpearmanRankProbe(activation.shape[1])\n",
    "y_probe = SpearmanRankProbe(activation.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c94d5f9f20446db524874bf7df39aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Spearman: 0.10022198850654593 | Loss: 112948079.7902078 | Weight norm: 0.5714514851570129\n",
      "Epoch: 1 | Train Spearman: 0.3922065448486283 | Loss: 76295613.21711253 | Weight norm: 0.5780867338180542\n",
      "Epoch: 2 | Train Spearman: 0.6189757966663403 | Loss: 47829540.383777015 | Weight norm: 0.5889997482299805\n",
      "Epoch: 3 | Train Spearman: 0.6221034367439727 | Loss: 47436930.20079649 | Weight norm: 0.6009981036186218\n",
      "Epoch: 4 | Train Spearman: 0.6465378466244557 | Loss: 44369700.85952272 | Weight norm: 0.6130351424217224\n",
      "Epoch: 5 | Train Spearman: 0.780946319196223 | Loss: 27497560.953787703 | Weight norm: 0.6244529485702515\n",
      "Epoch: 6 | Train Spearman: 0.7982189004868935 | Loss: 25329349.078375626 | Weight norm: 0.636198878288269\n",
      "Epoch: 7 | Train Spearman: 0.7723291698908743 | Loss: 28579253.30585622 | Weight norm: 0.6481263637542725\n",
      "Epoch: 8 | Train Spearman: 0.777418668247044 | Loss: 27940377.784400146 | Weight norm: 0.6598001718521118\n",
      "Epoch: 9 | Train Spearman: 0.8115468649645546 | Loss: 23656303.633454014 | Weight norm: 0.6711174249649048\n",
      "Epoch: 10 | Train Spearman: 0.8373891186410567 | Loss: 20412363.153550178 | Weight norm: 0.6820624470710754\n",
      "Epoch: 11 | Train Spearman: 0.8432769893979138 | Loss: 19673264.289952047 | Weight norm: 0.6925244927406311\n",
      "Epoch: 12 | Train Spearman: 0.8375390057560856 | Loss: 20393539.377147857 | Weight norm: 0.7023917436599731\n",
      "Epoch: 13 | Train Spearman: 0.8310287830621561 | Loss: 21210762.34177486 | Weight norm: 0.711732804775238\n",
      "Epoch: 14 | Train Spearman: 0.8349746196023133 | Loss: 20715442.532616008 | Weight norm: 0.7204497456550598\n",
      "Epoch: 15 | Train Spearman: 0.8467722082273588 | Loss: 19234508.316613596 | Weight norm: 0.7285854816436768\n",
      "Epoch: 16 | Train Spearman: 0.8569424886600979 | Loss: 17957847.562894013 | Weight norm: 0.7362852692604065\n",
      "Epoch: 17 | Train Spearman: 0.8607423083821488 | Loss: 17480862.87849463 | Weight norm: 0.7436049580574036\n",
      "Epoch: 18 | Train Spearman: 0.8599000778289303 | Loss: 17586586.13832177 | Weight norm: 0.7505820393562317\n",
      "Epoch: 19 | Train Spearman: 0.8588623337239493 | Loss: 17716852.162606843 | Weight norm: 0.7572288513183594\n",
      "Epoch: 20 | Train Spearman: 0.8621887872261619 | Loss: 17299280.922852743 | Weight norm: 0.7635300755500793\n",
      "Epoch: 21 | Train Spearman: 0.8674874606240306 | Loss: 16634147.936546557 | Weight norm: 0.7695220112800598\n",
      "Epoch: 22 | Train Spearman: 0.8739882171010901 | Loss: 15818112.22484687 | Weight norm: 0.775229811668396\n",
      "Epoch: 23 | Train Spearman: 0.8783286877867936 | Loss: 15273263.476383585 | Weight norm: 0.7806501388549805\n",
      "Epoch: 24 | Train Spearman: 0.8796755455821947 | Loss: 15104190.947238285 | Weight norm: 0.7857861518859863\n",
      "Epoch: 25 | Train Spearman: 0.878634257030057 | Loss: 15234905.475628935 | Weight norm: 0.7906079292297363\n",
      "Epoch: 26 | Train Spearman: 0.8785506752358132 | Loss: 15245392.153551545 | Weight norm: 0.7951412796974182\n",
      "Epoch: 27 | Train Spearman: 0.8805586033533807 | Loss: 14993343.837016685 | Weight norm: 0.7993966937065125\n",
      "Epoch: 28 | Train Spearman: 0.8841956236973143 | Loss: 14536787.625233425 | Weight norm: 0.8033593893051147\n",
      "Epoch: 29 | Train Spearman: 0.8877310179317219 | Loss: 14092997.463127399 | Weight norm: 0.8070374727249146\n",
      "Epoch: 30 | Train Spearman: 0.8891203169957389 | Loss: 13918598.339248128 | Weight norm: 0.8105467557907104\n",
      "Epoch: 31 | Train Spearman: 0.889542486473846 | Loss: 13865605.295871502 | Weight norm: 0.8138852119445801\n",
      "Epoch: 32 | Train Spearman: 0.8899235296756587 | Loss: 13817770.284303965 | Weight norm: 0.8170897364616394\n",
      "Epoch: 33 | Train Spearman: 0.8918156398547212 | Loss: 13580256.577757837 | Weight norm: 0.8201653957366943\n",
      "Epoch: 34 | Train Spearman: 0.8943433361831156 | Loss: 13262963.26660293 | Weight norm: 0.8230891227722168\n",
      "Epoch: 35 | Train Spearman: 0.896390527806085 | Loss: 13005976.258999487 | Weight norm: 0.8259097933769226\n",
      "Epoch: 36 | Train Spearman: 0.8972494255565177 | Loss: 12898163.800238058 | Weight norm: 0.8286253809928894\n",
      "Epoch: 37 | Train Spearman: 0.8975177907254057 | Loss: 12864474.966809776 | Weight norm: 0.831221878528595\n",
      "Epoch: 38 | Train Spearman: 0.8982047691655425 | Loss: 12778238.621325865 | Weight norm: 0.8336469531059265\n",
      "Epoch: 39 | Train Spearman: 0.8992787799908113 | Loss: 12643416.38523084 | Weight norm: 0.8359349966049194\n",
      "Epoch: 40 | Train Spearman: 0.9004153407961089 | Loss: 12500750.33677293 | Weight norm: 0.8381446003913879\n",
      "Epoch: 41 | Train Spearman: 0.9014668904287179 | Loss: 12368751.850462768 | Weight norm: 0.8402682542800903\n",
      "Epoch: 42 | Train Spearman: 0.9022597316607486 | Loss: 12269223.016150225 | Weight norm: 0.8422951102256775\n",
      "Epoch: 43 | Train Spearman: 0.9030128007764627 | Loss: 12174691.611076657 | Weight norm: 0.8442113995552063\n",
      "Epoch: 44 | Train Spearman: 0.9039456935583782 | Loss: 12057587.192191573 | Weight norm: 0.8460913300514221\n",
      "Epoch: 45 | Train Spearman: 0.904578417829888 | Loss: 11978163.860363634 | Weight norm: 0.8479401469230652\n",
      "Epoch: 46 | Train Spearman: 0.9047738108191005 | Loss: 11953631.22411932 | Weight norm: 0.8497072458267212\n",
      "Epoch: 47 | Train Spearman: 0.905191722432125 | Loss: 11901171.941168215 | Weight norm: 0.8513475656509399\n",
      "Epoch: 48 | Train Spearman: 0.905947782076207 | Loss: 11806273.91489317 | Weight norm: 0.852836549282074\n",
      "Epoch: 49 | Train Spearman: 0.9071549490044418 | Loss: 11654730.331732696 | Weight norm: 0.8542634844779968\n",
      "Epoch: 50 | Train Spearman: 0.9081424248458874 | Loss: 11530781.455958392 | Weight norm: 0.8555960655212402\n",
      "Epoch: 51 | Train Spearman: 0.908334572258636 | Loss: 11506657.011571757 | Weight norm: 0.8568097352981567\n",
      "Epoch: 52 | Train Spearman: 0.9080167356844779 | Loss: 11546552.279256372 | Weight norm: 0.8579767942428589\n",
      "Epoch: 53 | Train Spearman: 0.9093573337020439 | Loss: 11378269.792617254 | Weight norm: 0.859136164188385\n",
      "Epoch: 54 | Train Spearman: 0.9101484486828084 | Loss: 11278965.735123632 | Weight norm: 0.8602773547172546\n",
      "Epoch: 55 | Train Spearman: 0.9096133417030822 | Loss: 11346134.092004996 | Weight norm: 0.8614342212677002\n",
      "Epoch: 56 | Train Spearman: 0.9098034905098146 | Loss: 11322265.635098271 | Weight norm: 0.8625763058662415\n",
      "Epoch: 57 | Train Spearman: 0.9103573753047788 | Loss: 11252738.898478616 | Weight norm: 0.863705575466156\n",
      "Epoch: 58 | Train Spearman: 0.9111890635595965 | Loss: 11148336.163449075 | Weight norm: 0.8647465705871582\n",
      "Epoch: 59 | Train Spearman: 0.9110650368371213 | Loss: 11163906.969228849 | Weight norm: 0.8657768368721008\n",
      "Epoch: 60 | Train Spearman: 0.9110366547437234 | Loss: 11167465.571094496 | Weight norm: 0.8667252659797668\n",
      "Epoch: 61 | Train Spearman: 0.9119117972128634 | Loss: 11057612.867124805 | Weight norm: 0.8676474690437317\n",
      "Epoch: 62 | Train Spearman: 0.9134580162511617 | Loss: 10863515.490701644 | Weight norm: 0.8685547709465027\n",
      "Epoch: 63 | Train Spearman: 0.9141081451604818 | Loss: 10781902.548357515 | Weight norm: 0.869429349899292\n",
      "Epoch: 64 | Train Spearman: 0.9140827493612167 | Loss: 10785091.86699487 | Weight norm: 0.8703235983848572\n",
      "Epoch: 65 | Train Spearman: 0.9138932541288979 | Loss: 10808884.50241145 | Weight norm: 0.8712529540061951\n",
      "Epoch: 66 | Train Spearman: 0.9144549682206328 | Loss: 10738370.155713102 | Weight norm: 0.8721782565116882\n",
      "Epoch: 67 | Train Spearman: 0.9150956364471208 | Loss: 10657944.83405681 | Weight norm: 0.8730589747428894\n",
      "Epoch: 68 | Train Spearman: 0.914985591584866 | Loss: 10671760.212616717 | Weight norm: 0.8738998770713806\n",
      "Epoch: 69 | Train Spearman: 0.9147218017304718 | Loss: 10704879.19720365 | Weight norm: 0.8747222423553467\n",
      "Epoch: 70 | Train Spearman: 0.9152054586252026 | Loss: 10644158.46759248 | Weight norm: 0.8754884600639343\n",
      "Epoch: 71 | Train Spearman: 0.915709315112908 | Loss: 10580914.697216852 | Weight norm: 0.8762373924255371\n",
      "Epoch: 72 | Train Spearman: 0.9158188368982747 | Loss: 10567164.187961701 | Weight norm: 0.8768874406814575\n",
      "Epoch: 73 | Train Spearman: 0.9167819689557096 | Loss: 10446267.7088852 | Weight norm: 0.8774219751358032\n",
      "Epoch: 74 | Train Spearman: 0.9173395946775199 | Loss: 10376261.39237168 | Weight norm: 0.8779707551002502\n",
      "Epoch: 75 | Train Spearman: 0.917035825881864 | Loss: 10414394.476619888 | Weight norm: 0.8785210251808167\n",
      "Epoch: 76 | Train Spearman: 0.9159010723236182 | Loss: 10556838.416151153 | Weight norm: 0.8791233897209167\n",
      "Epoch: 77 | Train Spearman: 0.9157347946512528 | Loss: 10577716.058631282 | Weight norm: 0.8796870708465576\n",
      "Epoch: 78 | Train Spearman: 0.9174600996016141 | Loss: 10361143.280130371 | Weight norm: 0.8803547620773315\n",
      "Epoch: 79 | Train Spearman: 0.9178330557115457 | Loss: 10314319.529444695 | Weight norm: 0.881061315536499\n",
      "Epoch: 80 | Train Spearman: 0.9181528889441214 | Loss: 10274172.466796258 | Weight norm: 0.8817411661148071\n",
      "Epoch: 81 | Train Spearman: 0.9191084631126457 | Loss: 10154223.145046094 | Weight norm: 0.8823387622833252\n",
      "Epoch: 82 | Train Spearman: 0.9192230537773 | Loss: 10139836.979446083 | Weight norm: 0.882917046546936\n",
      "Epoch: 83 | Train Spearman: 0.9190518189661095 | Loss: 10161331.498694098 | Weight norm: 0.8834947347640991\n",
      "Epoch: 84 | Train Spearman: 0.919926249731136 | Loss: 10051566.96463987 | Weight norm: 0.884106457233429\n",
      "Epoch: 85 | Train Spearman: 0.9195555537724146 | Loss: 10098097.245451564 | Weight norm: 0.8847239017486572\n",
      "Epoch: 86 | Train Spearman: 0.9182487872832139 | Loss: 10262136.11714037 | Weight norm: 0.8853564858436584\n",
      "Epoch: 87 | Train Spearman: 0.9182150353208679 | Loss: 10266373.216412654 | Weight norm: 0.8859944343566895\n",
      "Epoch: 88 | Train Spearman: 0.9192717004024954 | Loss: 10133733.60517616 | Weight norm: 0.8866709470748901\n",
      "Epoch: 89 | Train Spearman: 0.9197893673726599 | Loss: 10068743.886863267 | Weight norm: 0.8873621821403503\n",
      "Epoch: 90 | Train Spearman: 0.9197295240086053 | Loss: 10076257.533084234 | Weight norm: 0.8880791068077087\n",
      "Epoch: 91 | Train Spearman: 0.9205165174635116 | Loss: 9977468.229680596 | Weight norm: 0.8888322710990906\n",
      "Epoch: 92 | Train Spearman: 0.9215427244292695 | Loss: 9848650.223670965 | Weight norm: 0.8895929455757141\n",
      "Epoch: 93 | Train Spearman: 0.9208267946428249 | Loss: 9938521.659227148 | Weight norm: 0.890296459197998\n",
      "Epoch: 94 | Train Spearman: 0.9207413602978259 | Loss: 9949251.473694343 | Weight norm: 0.8909381031990051\n",
      "Epoch: 95 | Train Spearman: 0.9218647572557148 | Loss: 9808225.39569662 | Weight norm: 0.8914925456047058\n",
      "Epoch: 96 | Train Spearman: 0.9216444014657 | Loss: 9835888.258210449 | Weight norm: 0.8920283317565918\n",
      "Epoch: 97 | Train Spearman: 0.9218541885088555 | Loss: 9809553.788060566 | Weight norm: 0.8925552368164062\n",
      "Epoch: 98 | Train Spearman: 0.9224868590446407 | Loss: 9730136.562199082 | Weight norm: 0.8930826783180237\n",
      "Epoch: 99 | Train Spearman: 0.9228271036464926 | Loss: 9687427.618731594 | Weight norm: 0.893608033657074\n",
      "Epoch: 100 | Train Spearman: 0.9222662645086116 | Loss: 9757827.476149095 | Weight norm: 0.894176185131073\n",
      "Epoch: 101 | Train Spearman: 0.9227151825276373 | Loss: 9701474.95634335 | Weight norm: 0.8947579264640808\n",
      "Epoch: 102 | Train Spearman: 0.9234384743413758 | Loss: 9610680.171702422 | Weight norm: 0.8953662514686584\n",
      "Epoch: 103 | Train Spearman: 0.924545443407763 | Loss: 9471721.211046092 | Weight norm: 0.8959807753562927\n",
      "Epoch: 104 | Train Spearman: 0.9245131428805599 | Loss: 9475777.23529248 | Weight norm: 0.8965727686882019\n",
      "Epoch: 105 | Train Spearman: 0.9245233936723354 | Loss: 9474491.490091847 | Weight norm: 0.8971210718154907\n",
      "Epoch: 106 | Train Spearman: 0.9248199470664811 | Loss: 9437264.379068445 | Weight norm: 0.8977017998695374\n",
      "Epoch: 107 | Train Spearman: 0.924947240323025 | Loss: 9421285.61876113 | Weight norm: 0.8982434868812561\n",
      "Epoch: 108 | Train Spearman: 0.924895422783423 | Loss: 9427791.266310615 | Weight norm: 0.8987404108047485\n",
      "Epoch: 109 | Train Spearman: 0.9253706006549504 | Loss: 9368145.985650815 | Weight norm: 0.8992051482200623\n",
      "Epoch: 110 | Train Spearman: 0.9256684129887006 | Loss: 9330761.805312041 | Weight norm: 0.8996669054031372\n",
      "Epoch: 111 | Train Spearman: 0.9251010504314144 | Loss: 9401981.425964795 | Weight norm: 0.900136411190033\n",
      "Epoch: 112 | Train Spearman: 0.926031150472297 | Loss: 9285224.542970298 | Weight norm: 0.9005497097969055\n",
      "Epoch: 113 | Train Spearman: 0.9258168299286592 | Loss: 9312129.554764 | Weight norm: 0.9009410738945007\n",
      "Epoch: 114 | Train Spearman: 0.9243364240368785 | Loss: 9497958.727994684 | Weight norm: 0.9013733267784119\n",
      "Epoch: 115 | Train Spearman: 0.9252432710964086 | Loss: 9384126.093195077 | Weight norm: 0.9018668532371521\n",
      "Epoch: 116 | Train Spearman: 0.9263507362133975 | Loss: 9245107.924516963 | Weight norm: 0.9023610353469849\n",
      "Epoch: 117 | Train Spearman: 0.9271657056646941 | Loss: 9142808.310916042 | Weight norm: 0.9029372334480286\n",
      "Epoch: 118 | Train Spearman: 0.9256307859118142 | Loss: 9335482.742860436 | Weight norm: 0.903556227684021\n",
      "Epoch: 119 | Train Spearman: 0.9248849655461823 | Loss: 9429101.942183357 | Weight norm: 0.9041633009910583\n",
      "Epoch: 120 | Train Spearman: 0.9259710561849243 | Loss: 9292766.993311906 | Weight norm: 0.9047542810440063\n",
      "Epoch: 121 | Train Spearman: 0.926125748215494 | Loss: 9273348.810083589 | Weight norm: 0.9052892923355103\n",
      "Epoch: 122 | Train Spearman: 0.9258848245337595 | Loss: 9303591.46081156 | Weight norm: 0.9057742953300476\n",
      "Epoch: 123 | Train Spearman: 0.9269897808104901 | Loss: 9164888.4589104 | Weight norm: 0.9063103199005127\n",
      "Epoch: 124 | Train Spearman: 0.9279847987541413 | Loss: 9039985.097518835 | Weight norm: 0.9068668484687805\n",
      "Epoch: 125 | Train Spearman: 0.9272272702576454 | Loss: 9135078.089942548 | Weight norm: 0.9074673056602478\n",
      "Epoch: 126 | Train Spearman: 0.9266265517629869 | Loss: 9210488.1120499 | Weight norm: 0.9081010818481445\n",
      "Epoch: 127 | Train Spearman: 0.9279630012982862 | Loss: 9042719.945868142 | Weight norm: 0.9087631106376648\n",
      "Epoch: 128 | Train Spearman: 0.9264203483451882 | Loss: 9236368.498320617 | Weight norm: 0.9094242453575134\n",
      "Epoch: 129 | Train Spearman: 0.9250742398157925 | Loss: 9405346.638005927 | Weight norm: 0.9100714921951294\n",
      "Epoch: 130 | Train Spearman: 0.9272395058264538 | Loss: 9133542.030203464 | Weight norm: 0.9106887578964233\n",
      "Epoch: 131 | Train Spearman: 0.929320201636464 | Loss: 8872354.095666988 | Weight norm: 0.911305844783783\n",
      "Epoch: 132 | Train Spearman: 0.9288922341347206 | Loss: 8926080.319308097 | Weight norm: 0.9119288921356201\n",
      "Epoch: 133 | Train Spearman: 0.9287501516797633 | Loss: 8943914.041453682 | Weight norm: 0.9125149846076965\n",
      "Epoch: 134 | Train Spearman: 0.9296351833271018 | Loss: 8832813.756780418 | Weight norm: 0.9130567312240601\n",
      "Epoch: 135 | Train Spearman: 0.9279903610636696 | Loss: 9039286.600629997 | Weight norm: 0.9136106371879578\n",
      "Epoch: 136 | Train Spearman: 0.9274402530922351 | Loss: 9108339.434895577 | Weight norm: 0.9141775369644165\n",
      "Epoch: 137 | Train Spearman: 0.9293454809061893 | Loss: 8869178.257575855 | Weight norm: 0.9147740006446838\n",
      "Epoch: 138 | Train Spearman: 0.9297659392893408 | Loss: 8816402.399628755 | Weight norm: 0.9153699278831482\n",
      "Epoch: 139 | Train Spearman: 0.9300137719695647 | Loss: 8785291.615245955 | Weight norm: 0.9159657955169678\n",
      "Epoch: 140 | Train Spearman: 0.9305644978203281 | Loss: 8716159.933288101 | Weight norm: 0.9165553450584412\n",
      "Epoch: 141 | Train Spearman: 0.9304053080846685 | Loss: 8736139.148109078 | Weight norm: 0.9170990586280823\n",
      "Epoch: 142 | Train Spearman: 0.9300892767607214 | Loss: 8775815.675265893 | Weight norm: 0.9176455140113831\n",
      "Epoch: 143 | Train Spearman: 0.9305060182150999 | Loss: 8723502.528131278 | Weight norm: 0.9181283116340637\n",
      "Epoch: 144 | Train Spearman: 0.930949506215663 | Loss: 8667828.450193746 | Weight norm: 0.9185996651649475\n",
      "Epoch: 145 | Train Spearman: 0.9312106817926195 | Loss: 8635038.83852726 | Weight norm: 0.919026792049408\n",
      "Epoch: 146 | Train Spearman: 0.9305078037741631 | Loss: 8723275.454534909 | Weight norm: 0.9194769263267517\n",
      "Epoch: 147 | Train Spearman: 0.9291690955387832 | Loss: 8891325.470922723 | Weight norm: 0.9199329614639282\n",
      "Epoch: 148 | Train Spearman: 0.9298894372017414 | Loss: 8800898.949645314 | Weight norm: 0.9204643368721008\n",
      "Epoch: 149 | Train Spearman: 0.9309115657284444 | Loss: 8672597.103224244 | Weight norm: 0.9210258722305298\n",
      "Epoch: 150 | Train Spearman: 0.9319095655442247 | Loss: 8547310.636780031 | Weight norm: 0.9216127395629883\n",
      "Epoch: 151 | Train Spearman: 0.93245678906251 | Loss: 8478620.343666108 | Weight norm: 0.9221873879432678\n",
      "Epoch: 152 | Train Spearman: 0.9325081525761709 | Loss: 8472177.021345783 | Weight norm: 0.9227489233016968\n",
      "Epoch: 153 | Train Spearman: 0.932206250268266 | Loss: 8510075.14841528 | Weight norm: 0.9232888221740723\n",
      "Epoch: 154 | Train Spearman: 0.9322099809474929 | Loss: 8509600.897523945 | Weight norm: 0.9238065481185913\n",
      "Epoch: 155 | Train Spearman: 0.9324603336121945 | Loss: 8478174.625768531 | Weight norm: 0.9243158102035522\n",
      "Epoch: 156 | Train Spearman: 0.9329159713954825 | Loss: 8420980.018221298 | Weight norm: 0.9247974753379822\n",
      "Epoch: 157 | Train Spearman: 0.932401231315007 | Loss: 8485596.973420275 | Weight norm: 0.9252684116363525\n",
      "Epoch: 158 | Train Spearman: 0.9313712625264222 | Loss: 8614884.428519115 | Weight norm: 0.9257461428642273\n",
      "Epoch: 159 | Train Spearman: 0.9304797033295402 | Loss: 8726802.194293194 | Weight norm: 0.9262393116950989\n",
      "Epoch: 160 | Train Spearman: 0.9330884690227415 | Loss: 8399327.254549496 | Weight norm: 0.9267066121101379\n",
      "Epoch: 161 | Train Spearman: 0.9321055096168179 | Loss: 8522719.356159545 | Weight norm: 0.9271756410598755\n",
      "Epoch: 162 | Train Spearman: 0.9315842814311874 | Loss: 8588141.650395524 | Weight norm: 0.9276381731033325\n",
      "Epoch: 163 | Train Spearman: 0.9334180459232422 | Loss: 8357953.910162588 | Weight norm: 0.9281160235404968\n",
      "Epoch: 164 | Train Spearman: 0.9336815853915186 | Loss: 8324877.700492703 | Weight norm: 0.9285891056060791\n",
      "Epoch: 165 | Train Spearman: 0.9334741704041691 | Loss: 8350906.093732071 | Weight norm: 0.9290456771850586\n",
      "Epoch: 166 | Train Spearman: 0.9338455632113726 | Loss: 8304292.5721785715 | Weight norm: 0.9294952750205994\n",
      "Epoch: 167 | Train Spearman: 0.9342925424607137 | Loss: 8248185.217605384 | Weight norm: 0.9299251437187195\n",
      "Epoch: 168 | Train Spearman: 0.9342457988305923 | Loss: 8254048.148273176 | Weight norm: 0.9303624033927917\n",
      "Epoch: 169 | Train Spearman: 0.9339394662904859 | Loss: 8292504.234433292 | Weight norm: 0.9307721257209778\n",
      "Epoch: 170 | Train Spearman: 0.9341991181131054 | Loss: 8259908.824686157 | Weight norm: 0.9311829805374146\n",
      "Epoch: 171 | Train Spearman: 0.934326847210324 | Loss: 8243872.974532037 | Weight norm: 0.9315816760063171\n",
      "Epoch: 172 | Train Spearman: 0.9341836608363239 | Loss: 8261846.726295305 | Weight norm: 0.9319806098937988\n",
      "Epoch: 173 | Train Spearman: 0.9350878509206898 | Loss: 8148347.509940585 | Weight norm: 0.9323769807815552\n",
      "Epoch: 174 | Train Spearman: 0.9353958537319393 | Loss: 8109680.50144001 | Weight norm: 0.932754635810852\n",
      "Epoch: 175 | Train Spearman: 0.9349951392951087 | Loss: 8159984.909029112 | Weight norm: 0.9331631660461426\n",
      "Epoch: 176 | Train Spearman: 0.9348430068926301 | Loss: 8179080.592285313 | Weight norm: 0.9335620999336243\n",
      "Epoch: 177 | Train Spearman: 0.9352995926231856 | Loss: 8121763.344591574 | Weight norm: 0.9339831471443176\n",
      "Epoch: 178 | Train Spearman: 0.9346606294391252 | Loss: 8201972.986556458 | Weight norm: 0.9343931674957275\n",
      "Epoch: 179 | Train Spearman: 0.9358485107811164 | Loss: 8052862.135596154 | Weight norm: 0.9347696304321289\n",
      "Epoch: 180 | Train Spearman: 0.9339127913899902 | Loss: 8295852.332252864 | Weight norm: 0.9351657629013062\n",
      "Epoch: 181 | Train Spearman: 0.9335817417880862 | Loss: 8337407.256364752 | Weight norm: 0.9355841875076294\n",
      "Epoch: 182 | Train Spearman: 0.9347796041747917 | Loss: 8187041.36387711 | Weight norm: 0.9360073804855347\n",
      "Epoch: 183 | Train Spearman: 0.9358633357258528 | Loss: 8051002.988363931 | Weight norm: 0.9364637136459351\n",
      "Epoch: 184 | Train Spearman: 0.9360667674001335 | Loss: 8025464.589981799 | Weight norm: 0.9369277358055115\n",
      "Epoch: 185 | Train Spearman: 0.9359209183841787 | Loss: 8043772.308895907 | Weight norm: 0.9373944401741028\n",
      "Epoch: 186 | Train Spearman: 0.9353076482681132 | Loss: 8120759.731971707 | Weight norm: 0.9378511309623718\n",
      "Epoch: 187 | Train Spearman: 0.9361971127101967 | Loss: 8009100.341436472 | Weight norm: 0.9382923245429993\n",
      "Epoch: 188 | Train Spearman: 0.9357044095392506 | Loss: 8070950.261353611 | Weight norm: 0.9387043714523315\n",
      "Epoch: 189 | Train Spearman: 0.9360807656429851 | Loss: 8023708.401179633 | Weight norm: 0.9391239285469055\n",
      "Epoch: 190 | Train Spearman: 0.9369459772070883 | Loss: 7915098.766671139 | Weight norm: 0.9395514130592346\n",
      "Epoch: 191 | Train Spearman: 0.9359099691323739 | Loss: 8045148.506759124 | Weight norm: 0.940002977848053\n",
      "Epoch: 192 | Train Spearman: 0.9359564889138898 | Loss: 8039307.433683003 | Weight norm: 0.9404528141021729\n",
      "Epoch: 193 | Train Spearman: 0.9366852949687762 | Loss: 7947818.782361751 | Weight norm: 0.9408990740776062\n",
      "Epoch: 194 | Train Spearman: 0.9363705225243647 | Loss: 7987334.115251865 | Weight norm: 0.941343367099762\n",
      "Epoch: 195 | Train Spearman: 0.9364186222604738 | Loss: 7981298.548600338 | Weight norm: 0.9418188333511353\n",
      "Epoch: 196 | Train Spearman: 0.9372187623063876 | Loss: 7880857.426789864 | Weight norm: 0.9423202276229858\n",
      "Epoch: 197 | Train Spearman: 0.9371404498926397 | Loss: 7890684.992360543 | Weight norm: 0.9428082704544067\n",
      "Epoch: 198 | Train Spearman: 0.9368561673471695 | Loss: 7926371.504398712 | Weight norm: 0.9432688355445862\n",
      "Epoch: 199 | Train Spearman: 0.9372156772372219 | Loss: 7881242.7057035575 | Weight norm: 0.9437388777732849\n"
     ]
    }
   ],
   "source": [
    "x_probe.fit(activation[~is_test], torch.tensor(x_train_rank), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bf27b9f27b447eaa1918bc124c0ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Spearman: 0.01816936670125411 | Loss: 123248065.23684348 | Weight norm: 0.5797871351242065\n",
      "Epoch: 1 | Train Spearman: 0.4747672266642869 | Loss: 65931881.259794876 | Weight norm: 0.5867290496826172\n",
      "Epoch: 2 | Train Spearman: 0.3182503177143465 | Loss: 85579264.76778036 | Weight norm: 0.595049262046814\n",
      "Epoch: 3 | Train Spearman: 0.3228203956253462 | Loss: 85005578.89105943 | Weight norm: 0.6061249375343323\n",
      "Epoch: 4 | Train Spearman: 0.3383313898828933 | Loss: 83058495.28968935 | Weight norm: 0.6179496049880981\n",
      "Epoch: 5 | Train Spearman: 0.3524687565347538 | Loss: 81283863.60998237 | Weight norm: 0.6300894021987915\n",
      "Epoch: 6 | Train Spearman: 0.36530454650737737 | Loss: 79672589.46455723 | Weight norm: 0.6422237157821655\n",
      "Epoch: 7 | Train Spearman: 0.3780266025276323 | Loss: 78075610.9699534 | Weight norm: 0.6541851162910461\n",
      "Epoch: 8 | Train Spearman: 0.3886648166907305 | Loss: 76740204.11233915 | Weight norm: 0.6658626198768616\n",
      "Epoch: 9 | Train Spearman: 0.39528748049025103 | Loss: 75908875.5423356 | Weight norm: 0.6772176623344421\n",
      "Epoch: 10 | Train Spearman: 0.39884279167274195 | Loss: 75462578.26417428 | Weight norm: 0.6881126761436462\n",
      "Epoch: 11 | Train Spearman: 0.40140366157260915 | Loss: 75141116.57015306 | Weight norm: 0.6983889937400818\n",
      "Epoch: 12 | Train Spearman: 0.40419399395959793 | Loss: 74790846.92330524 | Weight norm: 0.7080077528953552\n",
      "Epoch: 13 | Train Spearman: 0.4070673712769749 | Loss: 74430150.86037882 | Weight norm: 0.716960072517395\n",
      "Epoch: 14 | Train Spearman: 0.40979293417822177 | Loss: 74088012.26394154 | Weight norm: 0.7252902388572693\n",
      "Epoch: 15 | Train Spearman: 0.41204485015976716 | Loss: 73805336.24352232 | Weight norm: 0.7331240177154541\n",
      "Epoch: 16 | Train Spearman: 0.41424011066030786 | Loss: 73529771.61518486 | Weight norm: 0.7404487133026123\n",
      "Epoch: 17 | Train Spearman: 0.41679596004894764 | Loss: 73208934.43290228 | Weight norm: 0.7472923994064331\n",
      "Epoch: 18 | Train Spearman: 0.4195808831802922 | Loss: 72859348.4045803 | Weight norm: 0.7536876201629639\n",
      "Epoch: 19 | Train Spearman: 0.4224446441053166 | Loss: 72499858.91954657 | Weight norm: 0.759609580039978\n",
      "Epoch: 20 | Train Spearman: 0.4247530141642607 | Loss: 72210092.19986059 | Weight norm: 0.7651418447494507\n",
      "Epoch: 21 | Train Spearman: 0.42631005115370635 | Loss: 72014642.64366291 | Weight norm: 0.7703645825386047\n",
      "Epoch: 22 | Train Spearman: 0.42726157043426183 | Loss: 71895197.62417956 | Weight norm: 0.7752639651298523\n",
      "Epoch: 23 | Train Spearman: 0.42775848558399576 | Loss: 71832826.31609064 | Weight norm: 0.779887318611145\n",
      "Epoch: 24 | Train Spearman: 0.4281862947645049 | Loss: 71779120.84937206 | Weight norm: 0.7842551469802856\n",
      "Epoch: 25 | Train Spearman: 0.42862219967662224 | Loss: 71724400.68093948 | Weight norm: 0.7884036898612976\n",
      "Epoch: 26 | Train Spearman: 0.42923163351433113 | Loss: 71647904.07632041 | Weight norm: 0.7923488616943359\n",
      "Epoch: 27 | Train Spearman: 0.42964262724940766 | Loss: 71596308.81773293 | Weight norm: 0.7960305213928223\n",
      "Epoch: 28 | Train Spearman: 0.43064832513716855 | Loss: 71470066.61446011 | Weight norm: 0.7995575070381165\n",
      "Epoch: 29 | Train Spearman: 0.43164703680463984 | Loss: 71344697.76801477 | Weight norm: 0.802934467792511\n",
      "Epoch: 30 | Train Spearman: 0.4324667458374894 | Loss: 71241802.52263694 | Weight norm: 0.806137204170227\n",
      "Epoch: 31 | Train Spearman: 0.43325742266000344 | Loss: 71142549.53384383 | Weight norm: 0.8091543912887573\n",
      "Epoch: 32 | Train Spearman: 0.43393018740115624 | Loss: 71058098.37493096 | Weight norm: 0.8120201826095581\n",
      "Epoch: 33 | Train Spearman: 0.43444514865251305 | Loss: 70993452.84905426 | Weight norm: 0.8146657347679138\n",
      "Epoch: 34 | Train Spearman: 0.43486862610169486 | Loss: 70940296.41941637 | Weight norm: 0.8171522617340088\n",
      "Epoch: 35 | Train Spearman: 0.43520816739013907 | Loss: 70897675.34584537 | Weight norm: 0.8195207715034485\n",
      "Epoch: 36 | Train Spearman: 0.4355239865328051 | Loss: 70858023.98835564 | Weight norm: 0.8217655420303345\n",
      "Epoch: 37 | Train Spearman: 0.43606275907341563 | Loss: 70790397.42374955 | Weight norm: 0.8238635063171387\n",
      "Epoch: 38 | Train Spearman: 0.43676232314390795 | Loss: 70702580.34510621 | Weight norm: 0.8257434964179993\n",
      "Epoch: 39 | Train Spearman: 0.43756329905344926 | Loss: 70602034.45830242 | Weight norm: 0.8274537324905396\n",
      "Epoch: 40 | Train Spearman: 0.43839461274180297 | Loss: 70497678.74261536 | Weight norm: 0.829034686088562\n",
      "Epoch: 41 | Train Spearman: 0.4393529749985526 | Loss: 70377382.30268052 | Weight norm: 0.8304874300956726\n",
      "Epoch: 42 | Train Spearman: 0.4403027064838404 | Loss: 70258164.77881259 | Weight norm: 0.8318209052085876\n",
      "Epoch: 43 | Train Spearman: 0.4410345272414605 | Loss: 70166299.61991963 | Weight norm: 0.8330389261245728\n",
      "Epoch: 44 | Train Spearman: 0.44150631331134654 | Loss: 70107073.56768444 | Weight norm: 0.8342007398605347\n",
      "Epoch: 45 | Train Spearman: 0.44184664268429424 | Loss: 70064354.44199367 | Weight norm: 0.8353051543235779\n",
      "Epoch: 46 | Train Spearman: 0.44204668626167026 | Loss: 70039243.13407224 | Weight norm: 0.8363850116729736\n",
      "Epoch: 47 | Train Spearman: 0.44204697003205673 | Loss: 70039205.14098378 | Weight norm: 0.8374005556106567\n",
      "Epoch: 48 | Train Spearman: 0.4420368979010229 | Loss: 70040473.88464952 | Weight norm: 0.8384171724319458\n",
      "Epoch: 49 | Train Spearman: 0.4418851678543934 | Loss: 70059514.57181717 | Weight norm: 0.8393897414207458\n",
      "Epoch: 50 | Train Spearman: 0.4420037053338255 | Loss: 70044636.64239319 | Weight norm: 0.8403957486152649\n",
      "Epoch: 51 | Train Spearman: 0.44247984230290016 | Loss: 69984865.32686745 | Weight norm: 0.8414562344551086\n",
      "Epoch: 52 | Train Spearman: 0.4430470461828279 | Loss: 69913668.22986354 | Weight norm: 0.8425821661949158\n",
      "Epoch: 53 | Train Spearman: 0.4435487669263459 | Loss: 69850686.33926491 | Weight norm: 0.843755304813385\n",
      "Epoch: 54 | Train Spearman: 0.4436817347594877 | Loss: 69833995.76339221 | Weight norm: 0.8449738621711731\n",
      "Epoch: 55 | Train Spearman: 0.44344142395022534 | Loss: 69864164.70145968 | Weight norm: 0.846161425113678\n",
      "Epoch: 56 | Train Spearman: 0.443343525291422 | Loss: 69876446.24493055 | Weight norm: 0.847237765789032\n",
      "Epoch: 57 | Train Spearman: 0.4440452933848827 | Loss: 69788357.17269272 | Weight norm: 0.8481184840202332\n",
      "Epoch: 58 | Train Spearman: 0.44490007107376217 | Loss: 69681053.11354515 | Weight norm: 0.8489091396331787\n",
      "Epoch: 59 | Train Spearman: 0.4459815183271484 | Loss: 69545304.72572014 | Weight norm: 0.8496332168579102\n",
      "Epoch: 60 | Train Spearman: 0.4468939990899692 | Loss: 69430763.78482918 | Weight norm: 0.8503072261810303\n",
      "Epoch: 61 | Train Spearman: 0.4473939799284502 | Loss: 69367998.9641233 | Weight norm: 0.8510119318962097\n",
      "Epoch: 62 | Train Spearman: 0.4475439194999579 | Loss: 69349177.9481868 | Weight norm: 0.8517140746116638\n",
      "Epoch: 63 | Train Spearman: 0.4475937234831084 | Loss: 69342926.21629106 | Weight norm: 0.85246342420578\n",
      "Epoch: 64 | Train Spearman: 0.44770048458860423 | Loss: 69329530.46326342 | Weight norm: 0.8532435894012451\n",
      "Epoch: 65 | Train Spearman: 0.4476423530876905 | Loss: 69336821.78885408 | Weight norm: 0.8540182113647461\n",
      "Epoch: 66 | Train Spearman: 0.44822312198093167 | Loss: 69263921.49872765 | Weight norm: 0.8549103140830994\n",
      "Epoch: 67 | Train Spearman: 0.44897275387479446 | Loss: 69169823.54633969 | Weight norm: 0.8558486104011536\n",
      "Epoch: 68 | Train Spearman: 0.44939510931625654 | Loss: 69116801.03467107 | Weight norm: 0.8567960262298584\n",
      "Epoch: 69 | Train Spearman: 0.44949742508912327 | Loss: 69103956.777934 | Weight norm: 0.8576969504356384\n",
      "Epoch: 70 | Train Spearman: 0.4495213209285851 | Loss: 69100961.49433628 | Weight norm: 0.8585366606712341\n",
      "Epoch: 71 | Train Spearman: 0.44973209320591445 | Loss: 69074499.78078139 | Weight norm: 0.8593425750732422\n",
      "Epoch: 72 | Train Spearman: 0.4502763147970012 | Loss: 69006186.86811675 | Weight norm: 0.860062301158905\n",
      "Epoch: 73 | Train Spearman: 0.45094513174241807 | Loss: 68922226.95193547 | Weight norm: 0.8607063889503479\n",
      "Epoch: 74 | Train Spearman: 0.45129003256614014 | Loss: 68878932.83281733 | Weight norm: 0.8613624572753906\n",
      "Epoch: 75 | Train Spearman: 0.4514637112389567 | Loss: 68857132.04539645 | Weight norm: 0.862007200717926\n",
      "Epoch: 76 | Train Spearman: 0.45136003932643304 | Loss: 68870147.660809 | Weight norm: 0.8626400232315063\n",
      "Epoch: 77 | Train Spearman: 0.4514958484508692 | Loss: 68853095.96902762 | Weight norm: 0.8632906675338745\n",
      "Epoch: 78 | Train Spearman: 0.4524526449503586 | Loss: 68732994.71045777 | Weight norm: 0.864086389541626\n",
      "Epoch: 79 | Train Spearman: 0.45504878512134717 | Loss: 68407099.72089952 | Weight norm: 0.8649976849555969\n",
      "Epoch: 80 | Train Spearman: 0.45957430559907975 | Loss: 67839021.4584129 | Weight norm: 0.8660275340080261\n",
      "Epoch: 81 | Train Spearman: 0.4694692186262737 | Loss: 66596919.95142161 | Weight norm: 0.8673396110534668\n",
      "Epoch: 82 | Train Spearman: 0.49940319454938803 | Loss: 62839344.51740782 | Weight norm: 0.8691709041595459\n",
      "Epoch: 83 | Train Spearman: 0.5817556384172559 | Loss: 52501737.51435049 | Weight norm: 0.8717021942138672\n",
      "Epoch: 84 | Train Spearman: 0.7781038706870739 | Loss: 27854367.71548104 | Weight norm: 0.8753452897071838\n",
      "Epoch: 85 | Train Spearman: 0.8764125842534723 | Loss: 15513787.972458808 | Weight norm: 0.8804116249084473\n",
      "Epoch: 86 | Train Spearman: 0.7746221597113337 | Loss: 28291425.56789006 | Weight norm: 0.8864513635635376\n",
      "Epoch: 87 | Train Spearman: 0.7236397735846484 | Loss: 34691182.518193394 | Weight norm: 0.8925721049308777\n",
      "Epoch: 88 | Train Spearman: 0.7514556011876169 | Loss: 31199488.578367695 | Weight norm: 0.8984441757202148\n",
      "Epoch: 89 | Train Spearman: 0.8372790896593499 | Loss: 20426172.595520485 | Weight norm: 0.9042114019393921\n",
      "Epoch: 90 | Train Spearman: 0.8816168467099462 | Loss: 14860503.031247264 | Weight norm: 0.9101741313934326\n",
      "Epoch: 91 | Train Spearman: 0.8508053149875411 | Loss: 18728238.67374817 | Weight norm: 0.9163237810134888\n",
      "Epoch: 92 | Train Spearman: 0.8134217691667521 | Loss: 23420955.246775664 | Weight norm: 0.9225553870201111\n",
      "Epoch: 93 | Train Spearman: 0.8119369731137372 | Loss: 23607334.358637705 | Weight norm: 0.9286935925483704\n",
      "Epoch: 94 | Train Spearman: 0.842099795998783 | Loss: 19821032.55274761 | Weight norm: 0.9346808195114136\n",
      "Epoch: 95 | Train Spearman: 0.8811199333133714 | Loss: 14922879.241476607 | Weight norm: 0.9406105875968933\n",
      "Epoch: 96 | Train Spearman: 0.9025277736275475 | Loss: 12235576.46060008 | Weight norm: 0.9465156197547913\n",
      "Epoch: 97 | Train Spearman: 0.8841910535766674 | Loss: 14537363.830581116 | Weight norm: 0.9523397088050842\n",
      "Epoch: 98 | Train Spearman: 0.8534724569623612 | Loss: 18393437.197740354 | Weight norm: 0.9578517079353333\n",
      "Epoch: 99 | Train Spearman: 0.8454531595907558 | Loss: 19400089.831028074 | Weight norm: 0.9629178047180176\n",
      "Epoch: 100 | Train Spearman: 0.866891017369389 | Loss: 16709021.124587476 | Weight norm: 0.9675287008285522\n",
      "Epoch: 101 | Train Spearman: 0.8955457728128484 | Loss: 13112019.823238567 | Weight norm: 0.9718745946884155\n",
      "Epoch: 102 | Train Spearman: 0.9051981947426223 | Loss: 11900358.49907604 | Weight norm: 0.9760065674781799\n",
      "Epoch: 103 | Train Spearman: 0.8957041747430908 | Loss: 13092136.001665344 | Weight norm: 0.9800047874450684\n",
      "Epoch: 104 | Train Spearman: 0.8825142567790014 | Loss: 14747853.40118066 | Weight norm: 0.9838537573814392\n",
      "Epoch: 105 | Train Spearman: 0.8786355786697426 | Loss: 15234737.814276159 | Weight norm: 0.9875446557998657\n",
      "Epoch: 106 | Train Spearman: 0.88576722465867 | Loss: 14339508.816519251 | Weight norm: 0.9910802841186523\n",
      "Epoch: 107 | Train Spearman: 0.8968613986696882 | Loss: 12946868.237432381 | Weight norm: 0.9944605231285095\n",
      "Epoch: 108 | Train Spearman: 0.9028675587449095 | Loss: 12192926.95718836 | Weight norm: 0.997660756111145\n",
      "Epoch: 109 | Train Spearman: 0.9020497283804699 | Loss: 12295584.120743375 | Weight norm: 1.000662088394165\n",
      "Epoch: 110 | Train Spearman: 0.8970847339873541 | Loss: 12918833.118121268 | Weight norm: 1.0034558773040771\n",
      "Epoch: 111 | Train Spearman: 0.8946528008042172 | Loss: 13224111.711547725 | Weight norm: 1.0060449838638306\n",
      "Epoch: 112 | Train Spearman: 0.8990636321387492 | Loss: 12670426.483326284 | Weight norm: 1.0084280967712402\n",
      "Epoch: 113 | Train Spearman: 0.9060818907675282 | Loss: 11789431.647626972 | Weight norm: 1.0106127262115479\n",
      "Epoch: 114 | Train Spearman: 0.9093449626395385 | Loss: 11379822.93221267 | Weight norm: 1.0126646757125854\n",
      "Epoch: 115 | Train Spearman: 0.9075859301762018 | Loss: 11600631.958922818 | Weight norm: 1.0145982503890991\n",
      "Epoch: 116 | Train Spearman: 0.9033983934734675 | Loss: 12126287.892180096 | Weight norm: 1.0164214372634888\n",
      "Epoch: 117 | Train Spearman: 0.900418840635613 | Loss: 12500310.365175799 | Weight norm: 1.0181362628936768\n",
      "Epoch: 118 | Train Spearman: 0.902102904862734 | Loss: 12288909.629866052 | Weight norm: 1.0197672843933105\n",
      "Epoch: 119 | Train Spearman: 0.9075179217092432 | Loss: 11609169.052691808 | Weight norm: 1.0213186740875244\n",
      "Epoch: 120 | Train Spearman: 0.9110952766135332 | Loss: 11160111.873422604 | Weight norm: 1.0227830410003662\n",
      "Epoch: 121 | Train Spearman: 0.9108686419379198 | Loss: 11188558.494318346 | Weight norm: 1.0241674184799194\n",
      "Epoch: 122 | Train Spearman: 0.9085091639231558 | Loss: 11484742.004968 | Weight norm: 1.0254297256469727\n",
      "Epoch: 123 | Train Spearman: 0.9064847884834031 | Loss: 11738859.72237185 | Weight norm: 1.0266023874282837\n",
      "Epoch: 124 | Train Spearman: 0.9071932035755461 | Loss: 11649934.192836374 | Weight norm: 1.0277007818222046\n",
      "Epoch: 125 | Train Spearman: 0.9095612052569544 | Loss: 11352685.094498277 | Weight norm: 1.0287247896194458\n",
      "Epoch: 126 | Train Spearman: 0.9115308152400518 | Loss: 11105436.285211425 | Weight norm: 1.0296907424926758\n",
      "Epoch: 127 | Train Spearman: 0.9118069569257873 | Loss: 11070771.910919113 | Weight norm: 1.0306437015533447\n",
      "Epoch: 128 | Train Spearman: 0.9114662969026267 | Loss: 11113535.58542658 | Weight norm: 1.0315593481063843\n",
      "Epoch: 129 | Train Spearman: 0.9111276575730307 | Loss: 11156047.737193586 | Weight norm: 1.0324742794036865\n",
      "Epoch: 130 | Train Spearman: 0.9123690999426818 | Loss: 11000211.355904497 | Weight norm: 1.0333937406539917\n",
      "Epoch: 131 | Train Spearman: 0.9131809000597073 | Loss: 10898301.813306315 | Weight norm: 1.03425931930542\n",
      "Epoch: 132 | Train Spearman: 0.9129884456658721 | Loss: 10922459.942238396 | Weight norm: 1.0350466966629028\n",
      "Epoch: 133 | Train Spearman: 0.9119510276971432 | Loss: 11052686.788815575 | Weight norm: 1.0357483625411987\n",
      "Epoch: 134 | Train Spearman: 0.9118008878119792 | Loss: 11071537.127710715 | Weight norm: 1.0363951921463013\n",
      "Epoch: 135 | Train Spearman: 0.9136117250205917 | Loss: 10844222.47466734 | Weight norm: 1.0369452238082886\n",
      "Epoch: 136 | Train Spearman: 0.9153421648653557 | Loss: 10626997.523628766 | Weight norm: 1.037443995475769\n",
      "Epoch: 137 | Train Spearman: 0.9156328315984159 | Loss: 10590517.718165012 | Weight norm: 1.0379326343536377\n",
      "Epoch: 138 | Train Spearman: 0.9135266513774621 | Loss: 10854902.972527219 | Weight norm: 1.03842031955719\n",
      "Epoch: 139 | Train Spearman: 0.9100572138743582 | Loss: 11290419.59804129 | Weight norm: 1.0389024019241333\n",
      "Epoch: 140 | Train Spearman: 0.9097420233475279 | Loss: 11329974.711271383 | Weight norm: 1.0394408702850342\n",
      "Epoch: 141 | Train Spearman: 0.9126190460730895 | Loss: 10968832.121239888 | Weight norm: 1.0399794578552246\n",
      "Epoch: 142 | Train Spearman: 0.9152033112545022 | Loss: 10644435.676768593 | Weight norm: 1.0405369997024536\n",
      "Epoch: 143 | Train Spearman: 0.9152881341967198 | Loss: 10633784.92592956 | Weight norm: 1.0411025285720825\n",
      "Epoch: 144 | Train Spearman: 0.9136705236561004 | Loss: 10836838.381933592 | Weight norm: 1.0416685342788696\n",
      "Epoch: 145 | Train Spearman: 0.9136406621564939 | Loss: 10840591.050753301 | Weight norm: 1.0422035455703735\n",
      "Epoch: 146 | Train Spearman: 0.915998462099633 | Loss: 10544613.591999361 | Weight norm: 1.0427086353302002\n",
      "Epoch: 147 | Train Spearman: 0.9165435944163621 | Loss: 10476186.969963193 | Weight norm: 1.043209433555603\n",
      "Epoch: 148 | Train Spearman: 0.9153028652011337 | Loss: 10631932.950183623 | Weight norm: 1.043685793876648\n",
      "Epoch: 149 | Train Spearman: 0.9143449863299017 | Loss: 10752175.02777751 | Weight norm: 1.0441378355026245\n",
      "Epoch: 150 | Train Spearman: 0.9150735273454653 | Loss: 10660722.880966883 | Weight norm: 1.044569492340088\n",
      "Epoch: 151 | Train Spearman: 0.9172157338515206 | Loss: 10391813.23915959 | Weight norm: 1.0449739694595337\n",
      "Epoch: 152 | Train Spearman: 0.9184906767579643 | Loss: 10231773.7644801 | Weight norm: 1.0453786849975586\n",
      "Epoch: 153 | Train Spearman: 0.918031931283278 | Loss: 10289359.979507498 | Weight norm: 1.0457918643951416\n",
      "Epoch: 154 | Train Spearman: 0.9169262967736264 | Loss: 10428145.175986081 | Weight norm: 1.0462051630020142\n",
      "Epoch: 155 | Train Spearman: 0.9163439503682727 | Loss: 10501246.045711067 | Weight norm: 1.0465927124023438\n",
      "Epoch: 156 | Train Spearman: 0.916898166448071 | Loss: 10431679.802857544 | Weight norm: 1.0469821691513062\n",
      "Epoch: 157 | Train Spearman: 0.9179842251446172 | Loss: 10295346.417365728 | Weight norm: 1.0473543405532837\n",
      "Epoch: 158 | Train Spearman: 0.9183450502889898 | Loss: 10250051.935253715 | Weight norm: 1.0476996898651123\n",
      "Epoch: 159 | Train Spearman: 0.9170661987268821 | Loss: 10410587.435101911 | Weight norm: 1.0480314493179321\n",
      "Epoch: 160 | Train Spearman: 0.9168558327986001 | Loss: 10436991.931386396 | Weight norm: 1.048380970954895\n",
      "Epoch: 161 | Train Spearman: 0.9184988205779024 | Loss: 10230748.345539754 | Weight norm: 1.048730492591858\n",
      "Epoch: 162 | Train Spearman: 0.9197789879865692 | Loss: 10070053.485110259 | Weight norm: 1.0490747690200806\n",
      "Epoch: 163 | Train Spearman: 0.9197751226422912 | Loss: 10070536.047939884 | Weight norm: 1.0494109392166138\n",
      "Epoch: 164 | Train Spearman: 0.9188345391712479 | Loss: 10188608.862411475 | Weight norm: 1.0497676134109497\n",
      "Epoch: 165 | Train Spearman: 0.9182977819466737 | Loss: 10255985.01228295 | Weight norm: 1.05010986328125\n",
      "Epoch: 166 | Train Spearman: 0.918780189977774 | Loss: 10195430.838487558 | Weight norm: 1.050430417060852\n",
      "Epoch: 167 | Train Spearman: 0.9199838064323069 | Loss: 10044338.742154274 | Weight norm: 1.050723910331726\n",
      "Epoch: 168 | Train Spearman: 0.920438544840588 | Loss: 9987259.015492037 | Weight norm: 1.0510075092315674\n",
      "Epoch: 169 | Train Spearman: 0.9200188321547974 | Loss: 10039945.975458564 | Weight norm: 1.0512946844100952\n",
      "Epoch: 170 | Train Spearman: 0.9194074657512583 | Loss: 10116688.377664607 | Weight norm: 1.0515719652175903\n",
      "Epoch: 171 | Train Spearman: 0.9195410081058158 | Loss: 10099925.881750572 | Weight norm: 1.0518593788146973\n",
      "Epoch: 172 | Train Spearman: 0.9207169938225407 | Loss: 9952308.747632815 | Weight norm: 1.0521694421768188\n",
      "Epoch: 173 | Train Spearman: 0.9211231106584277 | Loss: 9901327.857770352 | Weight norm: 1.0524928569793701\n",
      "Epoch: 174 | Train Spearman: 0.9210249942218276 | Loss: 9913641.602196524 | Weight norm: 1.0527933835983276\n",
      "Epoch: 175 | Train Spearman: 0.921267453865857 | Loss: 9883205.333717877 | Weight norm: 1.0530871152877808\n",
      "Epoch: 176 | Train Spearman: 0.9213205901109658 | Loss: 9876536.245731922 | Weight norm: 1.0533761978149414\n",
      "Epoch: 177 | Train Spearman: 0.9214008221111968 | Loss: 9866462.244089914 | Weight norm: 1.0536668300628662\n",
      "Epoch: 178 | Train Spearman: 0.9215073896540458 | Loss: 9853086.79365223 | Weight norm: 1.053944706916809\n",
      "Epoch: 179 | Train Spearman: 0.9217194138678559 | Loss: 9826469.564747859 | Weight norm: 1.0542100667953491\n",
      "Epoch: 180 | Train Spearman: 0.9219257185317619 | Loss: 9800573.946143325 | Weight norm: 1.0544800758361816\n",
      "Epoch: 181 | Train Spearman: 0.9220042421393646 | Loss: 9790722.088923514 | Weight norm: 1.0547335147857666\n",
      "Epoch: 182 | Train Spearman: 0.9222530507437978 | Loss: 9759480.648106515 | Weight norm: 1.0549721717834473\n",
      "Epoch: 183 | Train Spearman: 0.9225386169188767 | Loss: 9723638.512882968 | Weight norm: 1.0552068948745728\n",
      "Epoch: 184 | Train Spearman: 0.9227694485523348 | Loss: 9694662.291859642 | Weight norm: 1.0554323196411133\n",
      "Epoch: 185 | Train Spearman: 0.9226530078206167 | Loss: 9709281.998962933 | Weight norm: 1.0556637048721313\n",
      "Epoch: 186 | Train Spearman: 0.9224920455602833 | Loss: 9729483.117260223 | Weight norm: 1.055893898010254\n",
      "Epoch: 187 | Train Spearman: 0.9226538806235318 | Loss: 9709169.451479144 | Weight norm: 1.0560930967330933\n",
      "Epoch: 188 | Train Spearman: 0.9229035280732644 | Loss: 9677830.114503091 | Weight norm: 1.0562998056411743\n",
      "Epoch: 189 | Train Spearman: 0.9232872829146079 | Loss: 9629658.006229565 | Weight norm: 1.0564842224121094\n",
      "Epoch: 190 | Train Spearman: 0.9234279406729091 | Loss: 9611998.899240604 | Weight norm: 1.056676983833313\n",
      "Epoch: 191 | Train Spearman: 0.9233987202150512 | Loss: 9615667.979273565 | Weight norm: 1.0568474531173706\n",
      "Epoch: 192 | Train Spearman: 0.9236479216722013 | Loss: 9584388.528589187 | Weight norm: 1.0570405721664429\n",
      "Epoch: 193 | Train Spearman: 0.9238700056426665 | Loss: 9556508.2826965 | Weight norm: 1.0572679042816162\n",
      "Epoch: 194 | Train Spearman: 0.9236827568180701 | Loss: 9580017.213050188 | Weight norm: 1.0575183629989624\n",
      "Epoch: 195 | Train Spearman: 0.9239512190640737 | Loss: 9546317.530054871 | Weight norm: 1.0577514171600342\n",
      "Epoch: 196 | Train Spearman: 0.924408266903038 | Loss: 9488939.656961046 | Weight norm: 1.0579931735992432\n",
      "Epoch: 197 | Train Spearman: 0.9239302535372147 | Loss: 9548949.135267481 | Weight norm: 1.058234453201294\n",
      "Epoch: 198 | Train Spearman: 0.9227819047860089 | Loss: 9693102.707452001 | Weight norm: 1.0584887266159058\n",
      "Epoch: 199 | Train Spearman: 0.9218945013727048 | Loss: 9804492.374204159 | Weight norm: 1.0587364435195923\n"
     ]
    }
   ],
   "source": [
    "y_probe.fit(activation[~is_test], torch.tensor(y_train_rank), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_vec = x_probe.get_feature_direction()\n",
    "projection = activation @ projection_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "projection_rank = rankdata(projection)\n",
    "plt.hist(projection_rank[~is_test], bins=100, alpha=0.5, label='train')\n",
    "plt.hist(projection_rank[is_test], bins=100, alpha=0.5, label='test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_rank = rankdata(x)\n",
    "\n",
    "plt.hist(x_rank[~is_test], bins=100, alpha=0.5, label='train')\n",
    "plt.hist(x_rank[is_test], bins=100, alpha=0.5, label='test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_vec_y = y_probe.get_feature_direction()\n",
    "projection_y = activation @ projection_vec_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "projection_rank_y = rankdata(projection_y)\n",
    "plt.hist(projection_rank_y[~is_test], bins=100, alpha=0.5, label='train')\n",
    "plt.hist(projection_rank_y[is_test], bins=100, alpha=0.5, label='test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_rank = rankdata(y)\n",
    "\n",
    "plt.hist(y_rank[~is_test], bins=100, alpha=0.5, label='train')\n",
    "plt.hist(y_rank[is_test], bins=100, alpha=0.5, label='test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('ord': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49f55f64751744ef6a80f6f4fc3ad3d9f6dd5829606d20fe83ee7b2ac92653b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
